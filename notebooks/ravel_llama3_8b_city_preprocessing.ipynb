{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(42)\n",
    "torch.set_default_device(\"cuda\")\n",
    "from transformers import LlamaForCausalLM, PreTrainedTokenizerFast, LlamaConfig, LlamaModel\n",
    "from torch import compile\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import transformers\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import contextlib\n",
    "import os\n",
    "import time\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'LlamaTokenizer'. \n",
      "The class this function is called from is 'PreTrainedTokenizerFast'.\n"
     ]
    }
   ],
   "source": [
    "from transformers import LlamaForCausalLM, PreTrainedTokenizerFast\n",
    "tokenizer = PreTrainedTokenizerFast.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v0.1\")\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = LlamaForCausalLM.from_pretrained(\"TinyLlama/TinyLlama-1.1B-Chat-v0.1\")\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "    \n",
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "\n",
    "tokenizer.padding_side = \"left\"\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering out 3 out of 3552 entities that the model does not know!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:03<00:00, 2875.14it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "type object 'Dataset' has no attribute 'from_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 125\u001b[0m\n\u001b[1;32m    122\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m Dataset\u001b[38;5;241m.\u001b[39mfrom_list(dataset)\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n\u001b[0;32m--> 125\u001b[0m city_train_set \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_ravel_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msplit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfiltering_dict_paths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./notebooks/ravel_llama-3-8b_city_prompt_to_output_statistics.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    126\u001b[0m city_test_set \u001b[38;5;241m=\u001b[39m  generate_ravel_dataset(\u001b[38;5;241m1000\u001b[39m, split\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, filtering_dict_paths\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./notebooks/ravel_llama-3-8b_city_prompt_to_output_statistics.json\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mravel_collate_fn\u001b[39m(batch):\n",
      "Cell \u001b[0;32mIn[4], line 122\u001b[0m, in \u001b[0;36mgenerate_ravel_dataset\u001b[0;34m(n_samples, split, domains, domain_excluded_attributes, filtering_dict_paths, seed)\u001b[0m\n\u001b[1;32m    110\u001b[0m             data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munaffected_attributes\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mappend(\n\u001b[1;32m    111\u001b[0m                 {\n\u001b[1;32m    112\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_text\u001b[39m\u001b[38;5;124m\"\u001b[39m: base_prompt,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    117\u001b[0m                 }\n\u001b[1;32m    118\u001b[0m             )\n\u001b[1;32m    120\u001b[0m         dataset\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[0;32m--> 122\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_list\u001b[49m(dataset)\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "\u001b[0;31mAttributeError\u001b[0m: type object 'Dataset' has no attribute 'from_list'"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from datasets import Dataset\n",
    "\n",
    "\n",
    "\n",
    "def generate_ravel_dataset(n_samples, split=\"train\", domains=[\"city\"], domain_excluded_attributes=[[\"Latitude\", \"Longitude\", \"Timezone\"]], filtering_dict_paths=[None],  seed=42):\n",
    "            \n",
    "    # Seed\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    dataset = []\n",
    "    \n",
    "    sample_per_domain = n_samples // len(domains)\n",
    "    \n",
    "    for domain, excluded_attributes, filtering_dict_path in zip(domains, domain_excluded_attributes, filtering_dict_paths):\n",
    "                        \n",
    "        templates = json.load(open(os.path.join(\"./data/ravel/\", f\"ravel_{domain}_attribute_to_prompts.json\"), \"r\"))\n",
    "        entities = json.load(open(os.path.join(\"./data/ravel/\", f\"ravel_{domain}_entity_attributes.json\"), \"r\"))\n",
    "        entities_split = json.load(open(os.path.join(\"./data/ravel/\", f\"ravel_{domain}_entity_to_split.json\"), \"r\"))\n",
    "        templates_split = json.load(open(os.path.join(\"./data/ravel/\", f\"ravel_{domain}_prompt_to_split.json\"), \"r\"))\n",
    "        \n",
    "        all_attributes = [a for a in list(templates.keys()) if a not in excluded_attributes]\n",
    "\n",
    "        templates_train = {k: [v for v in vs if templates_split[v] == \"train\"] for k, vs in templates.items()}\n",
    "        templates_train_idxs = {k: [templates[k].index(v) for v in vs if templates_split[v] == \"train\"] for k, vs in templates.items()}\n",
    "        \n",
    "        templates_test = {k: [v for v in vs if templates_split[v] != \"train\"] for k, vs in templates.items()}\n",
    "        templates_test_idxs = {k: [templates[k].index(v) for v in vs if templates_split[v] != \"train\"] for k, vs in templates.items()}\n",
    "\n",
    "        entities_train = {k: v for k, v in entities.items() if entities_split[k] == \"train\"}\n",
    "        name_train = list(entities_train.keys())\n",
    "\n",
    "        entities_test = {k: v for k, v in entities.items() if entities_split[k] != \"train\"}\n",
    "        name_test = list(entities_test.keys())\n",
    "        \n",
    "        if split == \"train\":\n",
    "            entity_dict, entity_name, prompt_dict, prompt_idxs_dict = entities_train, name_train, templates_train, templates_train_idxs\n",
    "        elif split == \"test\":\n",
    "            entity_dict, entity_name, prompt_dict, prompt_idxs_dict = entities_test, name_test, templates_test, templates_test_idxs\n",
    "        else:\n",
    "            raise ValueError(\"split must be 'train' or 'test'\")\n",
    "        \n",
    "        if filtering_dict_path is not None:\n",
    "            filtering_dict = json.load(open(filtering_dict_path, \"r\"))\n",
    "            filtered_key = []\n",
    "            \n",
    "            for entity in filtering_dict.keys():\n",
    "                model_knows = True\n",
    "                for attribute in all_attributes:                    \n",
    "                    split_template_idx = [list(filtering_dict[entity][attribute].values())[i] for i in prompt_idxs_dict[attribute]]\n",
    "                    if True not in split_template_idx:\n",
    "                        model_knows = False\n",
    "                        break\n",
    "                if not model_knows:\n",
    "                    filtered_key.append(entity)\n",
    "            print(f\"Filtering out {len(filtered_key)} out of {len(filtering_dict)} entities that the model does not know!\")\n",
    "            filtering_dict = {k: v for k, v in filtering_dict.items() if k not in filtered_key}\n",
    "        else:\n",
    "            filtering_dict = None\n",
    "        \n",
    "        for _ in tqdm(range(sample_per_domain)):\n",
    "            \n",
    "            data = {}\n",
    "            \n",
    "            if filtering_dict is None:\n",
    "                source_entity, base_entity = random.sample(entity_name, 2)\n",
    "                attribute = random.choice(all_attributes)\n",
    "                frozen_attributes = [k for k in all_attributes if k != attribute]\n",
    "                source_entity_dict, base_entity_dict = entity_dict[source_entity], entity_dict[base_entity]\n",
    "                source_template, base_template = random.choice(prompt_dict[attribute]), random.choice(prompt_dict[attribute])\n",
    "            else:\n",
    "                source_entity, base_entity = random.sample([k for k in entity_name if k in filtering_dict.keys()], 2)\n",
    "                attribute = random.choice(all_attributes)\n",
    "                frozen_attributes = [k for k in all_attributes if k != attribute]\n",
    "                source_entity_dict, base_entity_dict = entity_dict[source_entity], entity_dict[base_entity]\n",
    "                source_template_idxs = [i for i in range(len(filtering_dict[source_entity][attribute])) if filtering_dict[source_entity][attribute][str(i)] == True]\n",
    "                source_template_idxs = [prompt_idxs_dict[attribute].index(i) for i in source_template_idxs if i in prompt_idxs_dict[attribute]]\n",
    "                source_template = random.choice([prompt_dict[attribute][i] for i in source_template_idxs])\n",
    "                base_template_idxs = [i for i in range(len(filtering_dict[base_entity][attribute])) if filtering_dict[base_entity][attribute][str(i)] == True]\n",
    "                base_template_idxs = [prompt_idxs_dict[attribute].index(i) for i in base_template_idxs if i in prompt_idxs_dict[attribute]]\n",
    "                base_template = random.choice([prompt_dict[attribute][i] for i in base_template_idxs])\n",
    "                \n",
    "            data[\"input_text\"] = base_template % base_entity\n",
    "            data[\"counterfactual_input_text\"] = source_template % source_entity\n",
    "            data[\"edit_instruction\"] = f\"{base_entity} ; {source_entity} - {attribute}\"\n",
    "            data[\"target\"] = base_entity_dict[attribute]\n",
    "            data[\"counterfactual_target\"] = source_entity_dict[attribute]\n",
    "            \n",
    "            data[\"unaffected_attributes\"] = []\n",
    "            \n",
    "            for frozen_attribute in frozen_attributes:\n",
    "                \n",
    "                if filtering_dict is None:\n",
    "                    source_attribute_template, base_attribute_template = random.choice(prompt_dict[frozen_attribute]), random.choice(prompt_dict[frozen_attribute])\n",
    "                else:\n",
    "                    source_attribute_idxs = [i for i in range(len(filtering_dict[source_entity][frozen_attribute])) if filtering_dict[source_entity][frozen_attribute][str(i)] == True]\n",
    "                    source_attribute_idxs = [prompt_idxs_dict[frozen_attribute].index(i) for i in source_attribute_idxs if i in prompt_idxs_dict[frozen_attribute]]\n",
    "                    source_attribute_template = random.choice([prompt_dict[frozen_attribute][i] for i in source_attribute_idxs])\n",
    "                    base_attribute_idxs = [i for i in range(len(filtering_dict[base_entity][frozen_attribute])) if filtering_dict[base_entity][frozen_attribute][str(i)] == True]\n",
    "                    base_attribute_idxs = [prompt_idxs_dict[frozen_attribute].index(i) for i in base_attribute_idxs if i in prompt_idxs_dict[frozen_attribute]]\n",
    "                    base_attribute_template = random.choice([prompt_dict[frozen_attribute][i] for i in base_attribute_idxs])\n",
    "                    \n",
    "                base_prompt = base_attribute_template % base_entity\n",
    "                counterfactual_prompt = source_attribute_template % source_entity\n",
    "                \n",
    "                target = base_entity_dict[frozen_attribute]\n",
    "                counterfactual_target = source_entity_dict[frozen_attribute]\n",
    "                \n",
    "                data[\"unaffected_attributes\"].append(\n",
    "                    {\n",
    "                        \"input_text\": base_prompt,\n",
    "                        \"counterfactual_input_text\": counterfactual_prompt,\n",
    "                        \"edit_instruction\": f\"{base_entity} ; {source_entity} - {attribute}\",\n",
    "                        \"target\": target,\n",
    "                        \"counterfactual_target\": counterfactual_target,\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "            dataset.append(data)\n",
    "                \n",
    "    dataset = Dataset.from_list(dataset)\n",
    "    return dataset\n",
    "\n",
    "city_train_set = generate_ravel_dataset(10000, split=\"train\", filtering_dict_paths=[\"./notebooks/ravel_llama-3-8b_city_prompt_to_output_statistics.json\"])\n",
    "city_test_set =  generate_ravel_dataset(1000, split=\"test\", filtering_dict_paths=[\"./notebooks/ravel_llama-3-8b_city_prompt_to_output_statistics.json\"])\n",
    "\n",
    "def ravel_collate_fn(batch):\n",
    "    \n",
    "    def tokenize_text_inputs(texts, counterfactual_texts, target_texts):\n",
    "        \n",
    "        input_texts = [text + \" \" + target for text, target in zip(texts, target_texts)]\n",
    "        input_texts = [text.replace(\" \\\" \", \" \\\" \") for text in input_texts]\n",
    "        \n",
    "        tokenized = tokenizer(input_texts, return_tensors=\"pt\", padding=True, max_length=50, truncation=True)\n",
    "        tokenized_counterfactual = tokenizer(counterfactual_texts, return_tensors=\"pt\", padding=True, max_length=50, truncation=True)\n",
    "        tokenized_labels = []\n",
    "        \n",
    "        for input_ids, input_text in zip(tokenized[\"input_ids\"], texts):\n",
    "            input_length = tokenizer(input_text, return_tensors=\"pt\", padding=False)[\"input_ids\"].shape[-1]\n",
    "            label = torch.full_like(input_ids, -100)\n",
    "            label[input_length:] = input_ids[input_length:]\n",
    "            label[input_ids == tokenizer.pad_token_id] = -100\n",
    "            tokenized_labels.append(label)\n",
    "        \n",
    "        tokenized_labels = torch.stack(tokenized_labels)\n",
    "        return {\n",
    "            \"base_input_ids\": tokenized[\"input_ids\"],\n",
    "            \"base_attention_mask\": tokenized[\"attention_mask\"],\n",
    "            \"source_input_ids\": tokenized_counterfactual[\"input_ids\"],\n",
    "            \"source_attention_mask\": tokenized_counterfactual[\"attention_mask\"],\n",
    "            \"labels\": tokenized_labels\n",
    "        }\n",
    "        \n",
    "    prompts, edit_instructions, targets, unaffected_attributes, counterfactual_prompts = [], [], [], [], []\n",
    "    for b in batch:\n",
    "        prompts.append(b[\"input_text\"])\n",
    "        edit_instructions.append(b[\"edit_instruction\"])\n",
    "        targets.append(b[\"counterfactual_target\"])\n",
    "        unaffected_attributes.append(b[\"unaffected_attributes\"])\n",
    "        counterfactual_prompts.append(b[\"counterfactual_input_text\"])\n",
    "        \n",
    "        \n",
    "    editor_input_ids = tokenizer(edit_instructions, return_tensors=\"pt\", padding=True, truncation=True)[\"input_ids\"]\n",
    "    \n",
    "    returned_dict = {\n",
    "        \"editor_input_ids\": editor_input_ids,\n",
    "        **tokenize_text_inputs(prompts, counterfactual_prompts, targets),\n",
    "    }\n",
    "    \n",
    "    base_prompts_unaffected, counterfactual_prompts_unaffected, targets_unaffected, edit_instructions_unaffected, instance_indices = [], [], [], [], []\n",
    "    \n",
    "    for i, attribute_list in enumerate(unaffected_attributes):\n",
    "        \n",
    "        for d in attribute_list:\n",
    "            base_prompts_unaffected.append(d[\"input_text\"])\n",
    "            targets_unaffected.append(d[\"target\"])\n",
    "            counterfactual_prompts_unaffected.append(d[\"counterfactual_input_text\"])\n",
    "                    \n",
    "        for _ in range(len(attribute_list)):\n",
    "            edit_instructions_unaffected.append(editor_input_ids[i])\n",
    "            instance_indices.append(i)\n",
    "        \n",
    "    edit_instructions_unaffected = torch.stack(edit_instructions_unaffected)\n",
    "    instance_indices = torch.tensor(instance_indices)\n",
    "    \n",
    "    assert len(base_prompts_unaffected) == len(targets_unaffected)\n",
    "    \n",
    "    tokenized_unaffected = tokenize_text_inputs(base_prompts_unaffected, counterfactual_prompts_unaffected, targets_unaffected)\n",
    "    \n",
    "    returned_dict[\"editor_input_ids_unaffected\"] = edit_instructions_unaffected\n",
    "    returned_dict[\"base_input_ids_unaffected\"] = tokenized_unaffected[\"base_input_ids\"]\n",
    "    returned_dict[\"base_attention_mask_unaffected\"] = tokenized_unaffected[\"base_attention_mask\"]\n",
    "    returned_dict[\"source_input_ids_unaffected\"] = tokenized_unaffected[\"source_input_ids\"]\n",
    "    returned_dict[\"source_attention_mask_unaffected\"] = tokenized_unaffected[\"source_attention_mask\"]\n",
    "    returned_dict[\"labels_unaffected\"] = tokenized_unaffected[\"labels\"]\n",
    "    returned_dict[\"instance_indices\"] = instance_indices\n",
    "    \n",
    "    return returned_dict\n",
    "\n",
    "batch_size = 32  # 50 or so\n",
    "data_loader = DataLoader(\n",
    "    city_train_set, batch_size=batch_size, collate_fn=ravel_collate_fn, shuffle=True\n",
    ")  # batch_size, collate_fn=collate_fn)\n",
    "test_data_loader = DataLoader(\n",
    "    city_test_set, batch_size=batch_size, collate_fn=ravel_collate_fn, shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Currently have 0 samples:   0%|          | 0/625 [00:06<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Africa/Ndjamena 1.5 hours.\n",
      "False\n",
      "---------------\n",
      "Asia/Kolkata 1.\n",
      "False\n",
      "---------------\n",
      "Oceania Australia\"}, {\"\n",
      "False\n",
      "---------------\n",
      "Europe \n",
      "False\n",
      "---------------\n",
      "31 31\n",
      "True\n",
      "---------------\n",
      "31 31\n",
      "True\n",
      "---------------\n",
      "Bengali Bengali\"},\n",
      "True\n",
      "---------------\n",
      "-33 33.\n",
      "False\n",
      "---------------\n",
      "42 41\n",
      "False\n",
      "---------------\n",
      "Asia/Kuala_Lumpur 2019-12-31\n",
      "False\n",
      "---------------\n",
      "Africa \n",
      "False\n",
      "---------------\n",
      "India India\n",
      "True\n",
      "---------------\n",
      "-12 12\"}\n",
      "False\n",
      "---------------\n",
      "Russian 2\n",
      "False\n",
      "---------------\n",
      "Turkmenistan Turkey\"}, {\"city\n",
      "False\n",
      "---------------\n",
      "-57 60.\n",
      "False\n",
      "---------------\n",
      "[]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 115\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiltered \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(filtered_idx)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    113\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mselect(filtered_idx)\n\u001b[0;32m--> 115\u001b[0m filtered_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mfiltering_ravel_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcity_train_set\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m filtered_test_dataset \u001b[38;5;241m=\u001b[39m filtering_ravel_dataset(city_test_set, model, tokenizer)\n",
      "Cell \u001b[0;32mIn[14], line 110\u001b[0m, in \u001b[0;36mfiltering_ravel_dataset\u001b[0;34m(dataset, model, tokenizer, filtering_unaffected_features)\u001b[0m\n\u001b[1;32m    107\u001b[0m             filtered_idx\u001b[38;5;241m.\u001b[39mappend(i \u001b[38;5;241m+\u001b[39m step \u001b[38;5;241m*\u001b[39m batch_size)\n\u001b[1;32m    109\u001b[0m     \u001b[38;5;28mprint\u001b[39m(filtered_idx)\n\u001b[0;32m--> 110\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFiltered \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(filtered_idx)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m out of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m samples\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mselect(filtered_idx)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "def filtering_ravel_dataset(dataset, model, tokenizer, filtering_unaffected_features=True):\n",
    "    \n",
    "    def tokenize_text_inputs(texts, target_texts):\n",
    "        input_texts = [text + \" \" for text in texts]\n",
    "        input_texts = [text.replace(\" \\\" \", \" \\\" \") for text in input_texts]\n",
    "        \n",
    "        tokenized = tokenizer(input_texts, return_tensors=\"pt\", padding=True)\n",
    "        tokenized_labels = tokenizer(target_texts, return_tensors=\"pt\", padding=True)[\"input_ids\"]\n",
    "        tokenized_labels[tokenized_labels == tokenizer.pad_token_id] = -100\n",
    "        tokenized[\"labels\"] = tokenized_labels\n",
    "        return tokenized\n",
    "    \n",
    "    def filtering_collate_fn(batch):\n",
    "        prompts, targets, unaffected_attributes = [], [], []\n",
    "        for b in batch:\n",
    "            prompts.append(b[\"counterfactual_input_text\"])\n",
    "            targets.append(b[\"counterfactual_target\"])\n",
    "            unaffected_attributes.append(b[\"unaffected_attributes\"])\n",
    "        \n",
    "        returned_dict = {\n",
    "            **tokenize_text_inputs(prompts, targets),\n",
    "        }\n",
    "        \n",
    "        prompts_unaffected, targets_unaffected, instance_indices = [], [], []\n",
    "        \n",
    "        for i, attribute_list in enumerate(unaffected_attributes):\n",
    "    \n",
    "            for d in attribute_list:\n",
    "                prompts_unaffected.append(d[\"input_text\"])\n",
    "                targets_unaffected.append(d[\"target\"])\n",
    "                        \n",
    "            for _ in range(len(attribute_list)):\n",
    "                instance_indices.append(i)\n",
    "            \n",
    "        instance_indices = torch.tensor(instance_indices)\n",
    "        \n",
    "        assert len(prompts_unaffected) == len(targets_unaffected)\n",
    "        \n",
    "        tokenized_unaffected = tokenize_text_inputs(prompts_unaffected, targets_unaffected)\n",
    "        \n",
    "        returned_dict[\"input_ids_unaffected\"] = tokenized_unaffected[\"input_ids\"]\n",
    "        returned_dict[\"attention_mask_unaffected\"] = tokenized_unaffected[\"attention_mask\"]\n",
    "        returned_dict[\"labels_unaffected\"] = tokenized_unaffected[\"labels\"]\n",
    "        returned_dict[\"instance_indices\"] = instance_indices\n",
    "        \n",
    "        return returned_dict\n",
    "        \n",
    "    filtered_idx = []\n",
    "    \n",
    "    batch_size = 16  # 50 or so\n",
    "    data_loader = DataLoader(\n",
    "        dataset, batch_size=batch_size, collate_fn=filtering_collate_fn, shuffle=False, generator=torch.Generator(device='cuda')\n",
    "    )  # batch_size, collate_fn=collate_fn)\n",
    "    \n",
    "    model = model.to(\"cuda\")\n",
    "    model.eval()\n",
    "  \n",
    "    for step, batch in tqdm(enumerate(data_loader), total=len(data_loader), desc=f\"Currently have {len(filtered_idx)} samples\"):\n",
    "            \n",
    "        batch_pred_ids = model.generate(\n",
    "            input_ids=batch[\"input_ids\"].to(\"cuda\"),\n",
    "            attention_mask=batch[\"attention_mask\"].to(\"cuda\"),\n",
    "            max_new_tokens=10\n",
    "        )\n",
    "        \n",
    "        if filtering_unaffected_features:\n",
    "            batch_unaffected_pred_ids = model.generate(\n",
    "                input_ids=batch[\"input_ids_unaffected\"].to(\"cuda\"),\n",
    "                attention_mask=batch[\"attention_mask_unaffected\"].to(\"cuda\"),\n",
    "                max_new_tokens=10\n",
    "            )\n",
    "            \n",
    "            batch_instance_indices = batch[\"instance_indices\"]\n",
    "        else:\n",
    "            batch_unaffected_pred_ids = None\n",
    "            batch_instance_indices = None\n",
    "                        \n",
    "        for i, (label, pred_ids) in enumerate(zip(batch[\"labels\"], batch_pred_ids)):\n",
    "            \n",
    "            \n",
    "            output_idx = label != -100\n",
    "            label = label[output_idx]\n",
    "            pred_ids = pred_ids[len(batch[\"input_ids\"][i]):]\n",
    "            pred_ids = pred_ids[:len(label)]\n",
    "            print(tokenizer.decode(label, skip_special_tokens=True).strip(), tokenizer.decode(pred_ids, skip_special_tokens=True).strip())\n",
    "            is_correct = tokenizer.decode(label, skip_special_tokens=True).strip() in tokenizer.decode(pred_ids, skip_special_tokens=True).strip()\n",
    "            print(is_correct)\n",
    "            print(\"---------------\")\n",
    "            \n",
    "            if filtering_unaffected_features:\n",
    "                instance_unaffected_pred_ids = batch_unaffected_pred_ids[batch_instance_indices == i]\n",
    "                instance_unaffected_labels = batch[\"labels_unaffected\"][batch_instance_indices == i]\n",
    "                \n",
    "                for (unaffected_label, unaffected_pred_ids) in zip(instance_unaffected_labels, instance_unaffected_pred_ids):\n",
    "                    \n",
    "                    unaffected_output_idx = unaffected_label != -100\n",
    "                    unaffected_label = unaffected_label[unaffected_output_idx]\n",
    "                    unaffected_pred_ids = unaffected_pred_ids[len(batch[\"input_ids_unaffected\"][i]):]\n",
    "                    unaffected_pred_ids = unaffected_pred_ids[:len(unaffected_label)]\n",
    "                    \n",
    "                    unaffected_is_correct = tokenizer.decode(unaffected_label, skip_special_tokens=True).strip() in tokenizer.decode(unaffected_pred_ids, skip_special_tokens=True).strip()\n",
    "                    if not unaffected_is_correct:\n",
    "                        is_correct = False\n",
    "                        break\n",
    "        \n",
    "            if is_correct:\n",
    "                filtered_idx.append(i + step * batch_size)\n",
    "                \n",
    "        print(filtered_idx)\n",
    "        raise\n",
    "    \n",
    "    print(f\"Filtered {len(filtered_idx)} out of {len(dataset)} samples\")\n",
    "    return dataset.select(filtered_idx)\n",
    "\n",
    "filtered_dataset = filtering_ravel_dataset(city_train_set, model, tokenizer)\n",
    "filtered_test_dataset = filtering_ravel_dataset(city_test_set, model, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "subspace",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
