{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CUDA_VISIBLE_DEVICES=2\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from data import get_task, get_dataloader\n",
    "from helpers import ROOT_DIR\n",
    "from models.gpt2 import GPT2Editor\n",
    "\n",
    "torch.cuda.manual_seed(42)\n",
    "\n",
    "\n",
    "%env CUDA_VISIBLE_DEVICES=2\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8b28fdb30074dc9977000cf75ebe1d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=48):   0%|          | 0/1326278 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c539fa04918441adb3645fbe3c01c6c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/25 shards):   0%|          | 0/1326278 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from omegaconf import DictConfig\n",
    "\n",
    "cfg = DictConfig(\n",
    "    {\n",
    "        \"model\": {\"name_or_path\": \"gpt2\", \"max_length\": 512},\n",
    "        \"task\": {\n",
    "            \"name\": \"wikipedia\",\n",
    "            \"followup_char_limit\": 500,\n",
    "            \"editor_token_limit\": 50,\n",
    "        },\n",
    "        \"train\": {\"train_batch_size\": 1, \"validation_batch_size\": 1},\n",
    "        \"data\": {\n",
    "            \"test_split\": 0.1,\n",
    "            \"val_split\": 0.1,\n",
    "            \"n_examples\": 1000,\n",
    "            \"train_batch_size\": 2,\n",
    "            \"val_batch_size\": 2,\n",
    "        },\n",
    "        \"seed\": 42,\n",
    "    }\n",
    ")\n",
    "\n",
    "ds = get_task(cfg, \"wikipedia\", \"train\")\n",
    "\n",
    "dl = get_dataloader(ds, cfg, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "editor_input_ids tensor([[50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
      "         50256, 50256, 50256, 50256, 50256, 50256, 50256, 10606,   313,  2616,\n",
      "           357,    11, 14769,   313,   710,    11,   837, 14769,   313,    77,\n",
      "           726,    68,     8,   318,   257,  7404,   287,   262,  3454,   672,\n",
      "          8590,   544,  5665,   286,  3602,    77,   396,  7496,    11, 29684,\n",
      "         10071,    13]])\n",
      "target_input_ids tensor([[50256, 50256, 50256, 50256,  1026,   468,  1201,  6303,   587, 17169,\n",
      "           355,   257,   636,   286,   262,  2270,  8272,  1736,   312,    77,\n",
      "           395, 18657,   666, 29684,   615,   666,  2066,   357,  5868,    49,\n",
      "           737,   383,  3265,   286,   262,  7404,   318,  6108,   284,   510,\n",
      "           284,   604,  7319,   661,    11,  8384, 29684,   709,   504,    13]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "batch = next(iter(dl))\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(cfg.model.name_or_path)\n",
    "\n",
    "for k, v in batch.items():\n",
    "    if \"input_ids\" in k:\n",
    "        print(k,v)\n",
    "        # print(k, v.size(), tok.batch_decode(v, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.gpt2 import GPT2EditorConfig\n",
    "\n",
    "editor_model = GPT2Editor(GPT2EditorConfig()).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = editor_model(\n",
    "    editor_input_ids=torch.ones(1, 1).long().cuda(),\n",
    "    editor_attention_mask=torch.ones(1, 1).long().cuda(),\n",
    "    target_input_ids=torch.ones(1, 1).long().cuda(),\n",
    "    target_attention_mask=torch.ones(1, 1).long().cuda(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import slice_and_move_batch_for_device\n",
    "\n",
    "batch = next(iter(dl))\n",
    "out = editor_model(**slice_and_move_batch_for_device(batch, 0, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'editor_input_ids': torch.Size([2, 512]),\n",
       " 'editor_attention_mask': torch.Size([2, 512]),\n",
       " 'target_input_ids': torch.Size([2, 50]),\n",
       " 'target_attention_mask': torch.Size([2, 50])}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{k: v.shape for k, v in batch.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50256"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "editor_model.target_model.config.eos_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_utils import compute_ce_loss, compute_kl_loss\n",
    "\n",
    "with torch.no_grad():\n",
    "    # loss_ce = compute_ce_loss(editor_model, batch, 0, 1)\n",
    "    loss_kl = compute_kl_loss(editor_model, batch, 0, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "editor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
